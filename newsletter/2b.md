---
layout: newsletter.njk
title: "Don't Imitate Understand - #2"
desc: "Why AI Won't Replace Developers"
number: '2b'
og_image: 'assets/diu_newsletter.png'
---
# {{ title }}

Hello!
 
In this second issue of the "Don't Imitate Understand" newsletter you'll get:

- An extension of a discussion of a term I coined that I think is vital in the age of AI-supported software development.
- A bunch of interesting links!

<article class="mailing-list newsletter-mailing-list">
  <div id="fd-form-654c34a2f58f74816ab58ded"></div>
  <script>
    window.fd('form', {
      formId: '654c34a2f58f74816ab58ded',
      containerEl: '#fd-form-654c34a2f58f74816ab58ded'
    });
  </script>
</article>

## Entropy Tolerance: Why AI Won't Replace Developers

In my [latest blog post](https://tonyalicea.dev/blog/entropy-tolerance-ai/), I coined a new term I think is needed in the age of software development with AI. It's an extension of what we talked about in the last newsletter, dealing with the dangers of vibe coding.
 
**Entropy tolerance** is how much uncertainty (or AI-generated 'guesswork') a software-supported process can handle.
 
You can read the blog post for more details, but I wanted to expound more here on why this idea shows that AI and LLMs won't replace developers, and why as a dev you should be thinking about it.
 
The digital age was brought about because we were able to mathematically prove that a computational machine could consistently (i.e. deterministically) give the same outputs for the same set of inputs.
 
For that reason, we trust computers with things like airplane autopilots. If the computer randomly did unexpected things, that lack of trust would have prevented the entire digital age.
 
Yet, we constantly hear talking as if non-deterministic, probabilistic systems (LLMs) will replace developers and deterministic programs. This isn't just wrong; it's dangerous.
 
There are many processes that we support as developers that have low entropy tolerance. That means that the effects of hallucinations, inconsistencies, and mistakes are intolerable. Imagine if an LLM ran an autopilot and hallucinated that the pilot wanted to go to an incorrect destinationâ€¦or much worse.
 
Never forget that LLMs are sophisticated probability-based guessing machines. They don't truly reason. They guess what reasoning would look like. They are not deterministic, no matter how you tune them. That means they are inherently dangerous for use in critical processes.
 
As developers, we should get really good at using LLMs. They are a productivity super power. But their work needs human checks, and that isn't going away any time soon.
 
If a designer vibe codes some prototypes of a financial app, that's a process with high entropy tolerance, that's fine. But when it's time to build the financial app? That process has low entropy tolerance. It needs human devs to guide and check an AI's work.
 
AI simply will not replace developers. That's a mathematical and historical truth. Anyone saying otherwise is talking hype to investors, not to you.

## Links

I have a bunch of links for you this time around:

- [The people who build LLMs don't really understand how they work](https://www.anthropic.com/research/tracing-thoughts-language-model). LLM decisions aren't currently traceable.

- [The AI support bot for the popular Cursor IDE hallucinated and lied](https://www.theregister.com/2025/04/18/cursor_ai_support_bot_lies/).
- I dropped a [new YouTube video on source maps](https://youtu.be/9LKJ2pbrAlE?si=LtMeyNK0fU4VXV4S) (what they are and how they work) the unsung hero of modern web development.
- An interesting [web app that shrinks the size of your images](https://squoosh.app), but all locally (nothing sent to a server).
- The complexity of modern web frameworks means a greater surface area for possible security problems. Check out the [breakdown of a security issue](https://zhero-web-sec.github.io/research-and-things/react-router-and-the-remixed-path) that existed in React Router.
- [12 principles for building reliable LLM applications](https://github.com/humanlayer/12-factor-agents).
- My recent [blog post on doing rapid prototyping using LLMs](https://tonyalicea.dev/blog/grip-generative-rapid-prototyping/). I identify a set of 9 principles that together I call [GRiP](https://tonyalicea.dev/blog/grip-generative-rapid-prototyping/).
 
That's it for this second issue!
 
Happy coding!
 
Tony Alicea