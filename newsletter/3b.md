---
layout: newsletter.njk
title: "Don't Imitate Understand - #3"
desc: "Why Fundamentals Are More Important Than Ever"
number: '3b'
og_image: 'assets/diu_newsletter.png'
---
# {{ title }}

Hello!
 
In this third issue of the "Don't Imitate Understand" newsletter you'll get:

- A discussion of why strengthening your fundamentals is more important than ever in the age of AI.
- A bunch of interesting links!

<article class="mailing-list newsletter-mailing-list">
  <div id="fd-form-654c34a2f58f74816ab58ded"></div>
  <script>
    window.fd('form', {
      formId: '654c34a2f58f74816ab58ded',
      containerEl: '#fd-form-654c34a2f58f74816ab58ded'
    });
  </script>
</article>

## Why Fundamentals Are More Important Than Ever

There's a lot of talk right now about "upskilling." Everyone's talking about learning new AI tools, prompt engineering, and staying relevant in an AI-driven world. But AI is unreliable. It doesn't have a true concept of "correctness". It confabulates falsehoods. It can easily become a technical debt machine that pumps out reams of edge case bugs.

So let's coin a term for what you need as a developer in the age of AI. Not just upskilling, but **core skilling**.

Core skilling is about doubling down on the fundamental skills that have always been important, and will enable you to use AI successfully long-term. It's the opposite of what most people are doing right now. It may even make you indispensable.

## The Guidance Problem

AI is incredibly powerful, but it's also incredibly dangerous. It can generate thousands of lines of code, write compelling copy, and solve complex problems. But it has no wisdom about when its solutions are appropriate, scalable, or even correct.

The developers who will fully thrive with AI are the ones who can immediately spot when AI-generated code violates fundamental principles. They know when a solution is over-engineered, when it introduces security vulnerabilities, or when it will create maintenance headaches down the road. They can prompt properly because they understand what they need the AI to generate.

You can't guide what you don't understand. If you can't read the code AI generates and understand it, compare it to best practices, and know what needs to change, then you are doomed to future maintenance and security nightmares.

## The Validation Crisis

In organizations around the world people are using AI to generate work they couldn't create or validate themselves. Marketing teams are publishing AI-written content they can't fact-check. Pseudo-developers are shipping AI-generated code they can't debug. Analysts are presenting AI-created reports they can't verify.

This isn't productivity. It's outsourcing judgment to a system that fundamentally lacks it.

Fast AI generation coupled with slow validation and debugging can be worse than skipping AI generation entirely. Core skilling means understanding your domain so well that you can quickly recognize when AI output is useful versus when it's confidently wrong.

## The Wisdom Gap

The irony of the AI age is that fundamentals become more valuable, not less. When everyone has access to the same AI tools, differentiation comes from knowing how to wield them properly.

A developer with strong fundamentals can use AI to explore architectural possibilities they'd never have time to code by hand. A writer with deep subject matter expertise can use AI to rapidly iterate on ideas while maintaining accuracy and insight. A designer with solid UX, usability, and HCI principles can use AI to generate variations while ensuring the end result actually solves user problems.

But someone without those fundamentals? They're trusting a statistical probability machine to give them the right answer.

The thing that fundamentals provide but AI lacks can be summed up in one word: **"wisdom"**.

In the context of software development, we could define wisdom as the ability to apply knowledge and experience to solving a problem. Basically, it's *good judgment*.

You could argue that AI has a sum total of experience represented in its training data. But AI is not wise. It doesn't judge. It just guesses. Sometimes it guesses quite well. Sometimes it doesn't.

There's a massive gap between AI's knowledge and the thoughtful application of it. Guesswork is not wisdom.

## The Core Skilling Mindset

While you should learn how to use AI tools, you should build that knowledge on a solid understanding of your core discipline. Learn the patterns, principles, and mental models that let you evaluate any solution, AI-generated or otherwise.

For a web developer, for example, this would be fundamentals like HTTP, semantic HTML, modern CSS, and vanilla JavaScript, augmented with an understanding of how the JavaScript and browser rendering engines work under-the-hood.

AI should *amplify* your expertise, *not be a substitute for it*. Your fear shouldn't be becoming obsolete to AI, but to miss becoming indispensable alongside it.

In a time when anyone can generate content, code, or analysis with AI, those who understand what makes that output actually good will be the ones who thrive long-term.

So by all means upskill for AI. But you should also core skill for it. It's more important than ever.

## Links
- [Remix is leaving React behind](https://remix.run/blog/wake-up-remix). It's starting over as a fork of Preact.
- [A visual introduction to vector embeddings](https://blog.pamelafox.org/2025/05/a-visual-exploration-of-vector.html).
- [A realistic discussion of the unreliability of LLMs](https://verissimo.substack.com/p/verissimo-monthly-may-2025).
- [Addy Osmani's prompt engineering playbook for programmers](https://addyo.substack.com/p/the-prompt-engineering-playbook-for).

That's it for this third issue!
 
Happy coding!
 
Tony Alicea