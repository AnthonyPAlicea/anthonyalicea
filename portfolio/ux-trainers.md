---
layout: portfolio.njk
title: "Training the Trainers"
subtitle: "Developing a repeatable framework for producing clear, effective technical education at scale."
category: "Curriculum Design"
role: "Curriculum Lead & Instructor Coach"
timeline: "2018 – Present"
team: "Collaborated with 6+ instructors and production staff"
excerpt: "How I developed a structured approach to help technical instructors create clearer, more learner-centered courses — and why managing educational quality is a UX problem."
---

<div class="image-placeholder image-placeholder--wide"></div>

## Context

Over the past several years, I've authored courses on JavaScript, Node.js, HTML, CSS, and UX that have reached hundreds of thousands of learners on platforms like Udemy and Pluralsight. Early on, I realized that *making* a great course is only half the challenge. The other half is understanding how to **teach others to do it consistently**.

As I moved from individual contributor to mentor and advisor — helping newer instructors structure their own material — I found myself building a system. This case study captures that framework and what it taught me about scaling educational quality.

## The Problem

Technical education has a well-known gap: subject matter expertise doesn't automatically translate into effective teaching. Brilliant engineers often produce courses that are dense, poorly paced, or structured around the *topic's* logic rather than the *learner's* journey.

When working with other instructors, I saw common patterns:

- Lessons structured around feature lists rather than conceptual progression
- Cognitive overload from trying to cover too much in a single module
- Missing "bridge" moments — the connective tissue that helps learners see *why* something matters before diving into *how*

> The core insight: the learner's experience of a course **is** a user experience. Every moment of confusion is a usability problem.

## Approach

### Learner-Centered Course Architecture

I developed a lightweight planning process that every instructor could adapt to their own teaching style:

1. **Start with the transformation** — Define what the learner should be able to *do* after the course, not just what they should *know*
2. **Map the conceptual dependency graph** — Identify which ideas depend on which, and sequence them accordingly
3. **Design for pacing** — Alternate between concept introduction, demonstration, and practice. No section should sustain a single mode for too long

<div class="image-placeholder"></div>

### The Feedback Loop

Rather than reviewing finished courses (when it's expensive to change anything), I introduced structured checkpoints:

- **Outline review** — Before any recording, walk through the course arc together. Does each section earn the learner's attention for the next?
- **First-module review** — After recording the opening section, assess tone, pacing, and clarity. Adjustments here are cheap; later they're costly
- **Learner data review** — After launch, examine drop-off points and Q&A patterns to refine future iterations

### A Shared Language for Quality

The hardest part of coaching isn't identifying problems — it's giving feedback that people can act on. I built a simple rubric focused on four qualities:

- **Clarity** — Can the learner follow without rewinding?
- **Motivation** — Does the learner understand why this matters *before* the explanation?
- **Pacing** — Is there room to absorb, or does it feel rushed?
- **Accuracy** — Is the content technically sound and current?

This gave both instructors and reviewers a shared vocabulary, turning subjective feedback ("this feels off") into actionable direction ("the motivation for this section is missing").

<div class="image-placeholder"></div>

## Results

- Instructors I coached reported feeling **more confident** structuring new material independently
- Courses developed with this framework saw **higher completion rates** and **more positive qualitative feedback** from learners
- The rubric became a self-assessment tool — instructors began catching issues in their own work before review

## Reflection

What made this work wasn't the framework itself — it was treating instructor enablement as a design problem. The instructors were my users. Their workflow was the experience. The rubric was the interface.

This is the same work, whether you're improving a checkout flow or a course outline: **understand the person doing the task, remove unnecessary friction, and give them tools that make quality the path of least resistance.**

That's why I'm drawn to the work at Nielsen Norman Group — building and guiding a team that produces world-class UX education is, at its core, a UX challenge. And it's one I've been practicing for years.
